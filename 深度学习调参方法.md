# **深度学习调参方法**

**Varun Godbole†, George E. Dahl†, Justin Gilmer†, Christopher J. Shallue‡, Zachary Nado†**

† Google Research, Brain Team

‡ Harvard University

## 开始新的工程的指南

​		许多调参的决定只在工程开始时设置，当一些条件发生变化时才会再去回顾或改变。

​		我们该部分的指南基于以下假设：

* 问题构建、数据清理等主要工作已经完成，因此，只需将时间花在模型架构和训练配置
* 已经有流水线用来进行模型训练和评估，并且，对所感兴趣的不同模型都可以较容易地进行训练和预测工作
* 合适的评估标准已经选择并设置。这些应该尽可能对部署环境下的测量有代表性



### 选择合适的模型架构

***总结***：当开始一个新的工程时，试着复用已经有效果的模型

* 首先，选择一个很好构建、普遍使用的模型架构来开展工作。总是可以在后面再建立一个定制化的模型

* 模型架构一般都具有多种超参数，这些超参数决定了模型的尺寸和其他一些细节（如，层数，层宽，激活函数的类型）
  * 因此，选择一个架构，实际意味着选择一族不同模型（一组模型超参数的设置即为一族）
  * 我们将在选择初始设置和提升模型性能的科学方法中研究如何选择模型超参数的问题

*如果可能的话，试着寻找一篇与手头工作尽可能接近的论文，并复现该模型作为开始



### 选择优化器

***总结***：以对手头问题最流行的优化器来开始

* 对于所有类型的机器学习问题和模型架构，没有哪个优化器是最优的。甚至，比较不同优化器也是个困难的任务。
* 我们推荐以流行的优化器，特别是当开始一个新的工程。
  * 理想的，对相同类型的问题选择最流行的优化器

* 应对所选择的优化器的所有超参数给予重视。
  * 具有更多超参数的优化器可能需要更多的调节努力来寻找最佳设置
  * 这特别的相对在工程开始阶段，当我们寻找其他多种超参数的最佳值（如，架构超参数）而对优化器超参数为麻烦的参数
  * 也许在工程开始阶段，使用较简单的优化器（如，固定动量的SGD或固定参数的Adam）更合适，在以后再转向更一般的优化器

* 我们喜欢公认的优化器包括（但不局限于）
  * 动量SGD（我们喜欢Nesterov变种）
  * Adam和NAdam，比动量SGD更一般。注意，Adam有4个可调节超参数。

### 选择batch size

***总结***：batch size控制着训练速度，不应被用于直接调节验证集的性能。通常，理想的batch size是现有硬件所支持的最大的batch size。
* batch size是决定训练时间和计算资源消耗的关键参数
* 增加batch size通常可以降低训练时间。这是非常有用的，因为
  * 在固定的时间间隔内，使得超参数可以被调节更多次，潜在地导致更好的最终模
  * 减小开发周期的等待时间，使得新的idea能够更频繁地被测试

* 增加batch size可能会降低、增加或不改变资源消耗
* batch size不该被视作用于改变验证集性能的可调节超参数
  * 只要所有超参数已经被很好地调节（特别是学习速率和正则化超参数），以及训练步数是足够的，那么，对于任意batch size都能得到相同的最终性能(Shallue et al. 2018)
  * 可以查看为什么不应该直接调节batch size 来提升验证集的性能

#### 确定可行的batch size和估计训练吞吐量(throughput)

* 对于给定的模型和优化器，现有硬件一般支持一定范围的batch size。这限制因素通常为内存
* 不幸的是，不进行运行或编译完整的训练程序，是很难计算适合内存的batch size
* 最简单的解决方法，通常是用较少步数分别训练一系列不同batch size，直到其中一个job超过了现有内存
* 对于每个batch size，我们应该训练足够长的时间来获得对训练吞吐量的可靠估计。

   ​	训练吞吐量 =（ 每秒处理的样本数） 或 （每个step所需时间）

   ​	每个step所需时间 = （batch size）/ （训练吞吐量）

* 当加速器还没达到饱和，如果加倍batch size，则训练吞吐量也应加倍（或至少接近加倍）。相当于，当batch size增加，每一步的时长应为恒值（至少近似恒值）
* 如果不是这种情况，那么训练流水线会有其他瓶颈，如，IO或在计算节点间的同步。这值得在下一步进行之前先诊断和修正。
* 如果训练吞吐量只在一定大的batch size会增加，那么，我们只考虑这种大小batch size，即使硬件支持更大的batch size
  * 使用更大的batch size的好处是基于训练吞吐量会增加。如果没有满足这种假设，那么应修复这些瓶颈或使用更小的batch size
  * **梯度累加**模拟比硬件支持的最大batch size，因此，不会得到任何吞吐量的好处。这一般在实际工作中应避免。

* 这些步骤可能在每次模型或优化器发生改变时都要重复进行（如，不同的模型架构可能运行更大的batch size适合内存）

 

#### 选择batch size来使得训练时间最小化

训练时长 = （每个step时长）* （总step数）

* 我们通常可以认为，对于所有可行的batch size，每个step的时间都是近似恒定的。当并行计算没有开销并且所有训练瓶颈都已被诊断和纠正时，这是正确的。实际上，增加batch size通常至少会产生一些开销。

* 随着batch size的增加，达到固定性能目标所需的步数通常会减少（Shallue et al. 2018 给出了当batch size发生改变时，重调所有相关超参数的方法）
  * 例如，加倍batch size可能会使得所需步数减半。这被称为是完美尺度化。
  * 在达到临界batch size之前，完美尺度化对所有batch size都是成立的；超过该临界值后，得到的回报将递减
  * 最终，增加batch size不再减少训练所需步数（但从不会增加步数）

* 因此，最小化训练时间的batch size，通常是最大的batch size仍能减小所需的训练步数。
  * 这个批量大小取决于数据集、模型和优化器，除了通过实验为每个新问题找到它之外，如何计算它是一个悬而未决的问题
  * 当比较不同batch size时，需注意单个样本开销/epoch开销(当固定训练样本数时训练所有实验)和单个step的开销(固定训练步数来训练所有实验)
    * 将批量大小与 epoch 预算进行比较只会探索完美的扩展机制，即使更大的批量大小仍可能通过减少所需的训练步骤数来提供有意义的加速
  * 通常，硬件所支持的最大batch size会比临界batch size要小一些。因此，好的做法是（没有跑任何实验）尽可能使用最大的batch size。

1. 如果最终会增加训练时间，那么使用更大的批量大小是没有意义的



#### 选择使得资源开销最小化的batch size

* 伴随着batch size的增加，有两种类型的资源开销
* 如果增加批量大小的前期成本很高，那么最好推迟增加批量大小，直到项目成熟并且更容易评估成本效益权衡。 实施多主机并行训练程序可能会引入错误和细微问题，因此最好从更简单的管道开始。 （另一方面，在需要大量调整实验的过程早期，训练时间的大幅加快可能非常有益）
* 我们将总的使用成本（可能包括多种不同的成本）称为“资源消耗”。 我们可以将资源消耗分解为以下组成部分：

   资源消耗 = （每个step的资源消耗）* （总step数量）
* 增加batch size通常可以让我们减少总步数。 资源消耗是增加还是减少将取决于每步消耗如何变化
  * 增加批大小可能会减少资源消耗。 例如，如果具有较大batch size的每个step都可以在与较小批量大小相同的硬件上运行（每个step的时间只增加一点点），那么每个step资源消耗的增加可能会被步数上的减少所抵消。
  * 增加batch size可能不会改变资源消耗。例如，如果加倍batch size来使所需step减半和加倍所需GPU数量，那么总的消耗（GPU小时）不会改变。
  * 增加batch size可能增加资源消耗。例如，如果增加batch size会需要升级硬件，每个step的消耗的增加可能会被step数量的减少而抵消。



#### 改变batch size会需要重调大部分超参数

* 大部分超参数的最优值都是对batch size敏感的。因此，当改变batch size时，一般都需要重新调参
* 和batch size相关性最强的超参数是优化器超参数（如，学习速率和动量）和正则化超参数，因此，需要对每个batch size单独调参。
* 在项目开始时选择批量大小时请记住这一点。 如果您以后需要切换到不同的批量大小，则为新的批量大小重新调整所有内容可能会很困难、耗时且昂贵。



#### Batch norm如何与batch size相互影响

​	Batch norm 很复杂，一般来说，应该使用与梯度计算不同的 batch size 来计算统计数据。 有关详细讨论，请参阅batch norm部分

### 选择初始配置

* 在开始进行超参数调参前，必须先确定开始点。这包含确定，(1)模型配置(如，层数)，(2) 优化器超参数(如，学习速率)，(3) 训练步数
* 确定此初始配置将需要一些手动配置的训练运行和反复试验
* 我们的指导原则是找到一种简单、相对快速、相对低资源消耗的配置，以获得“合理”的结果  
  * “简单”意味着尽可能避免花里胡哨的东西； 这些总是可以在以后添加。 即使花里胡哨的东西在未来被证明是有用的，但在初始配置中添加它们可能会浪费时间调整无用的功能和/或烘烤不必要的并发症。**如，在添加花哨的decay schedules之前，以恒定的学习速率开始**
  * 选择快速且消耗最少资源的初始配置将使超参数调整更加高效。**如，以较小的模型开始**
  * “合理”性能取决于问题，但至少意味着经过训练的模型在验证集上的性能比随机机会好得多（尽管它可能很糟糕，不值得部署）
* 选择训练步数涉及到平衡以下方面：
  * 一方面，训练更多的步数，可以提升性能，使得超参数调节变得更容易
  * 另一方面，使用更少的步数训练，可以使得每次训练更快和使用更少的资源，通过减少循环之间的时间并允许并行运行更多实验来提高调优效率。 此外，如果最初选择了一个不必要的大步预算，可能很难在以后改变它，例如 一旦针对该步数调整了学习率计划

## 提升模型性能的科学方法

就本文档而言，机器学习开发的最终目标是最大化已部署模型的效用。 尽管开发过程的许多方面因应用程序而异（例如时间长度、可用计算资源、模型类型），但我们通常可以在任何问题上使用相同的基本步骤和原则。  
下面的指南做了以下假设：

* 已经有一个能够完整运行的训练pipeline并能够得到合理结果的配置
* 有足够的计算资源可用于进行有意义的调整实验并并行运行至少多个训练作业

### 增量调节策略

***总结***：从简单的配置开始，逐步进行改进，同时深入了解问题。 确保任何改进都基于强有力的证据，以避免增加不必要的复杂性。

* 我们的最终目标是找到一个能最大化我们模型性能的配置
  * 在某些情况下，我们的目标是在固定的截止日期前最大限度地改进模型（例如提交竞赛）。
  * 在其他情况下，我们希望无限期地改进模型（例如，不断改进生产中使用的模型）。
* 原则上，我们可以通过使用算法自动搜索可能配置的整个空间来最大化性能，但这不是一个实用的选择。
  * 可能配置的空间非常大，目前还没有任何算法足够复杂，可以在没有人工指导的情况下有效地搜索这个空间
* 大多数自动搜索算法都依赖于手动设计的搜索空间，该搜索空间定义了要搜索的配置集，这些搜索空间可能非常重要。
* 最大化性能的最有效方法是从简单的配置开始，逐步添加功能并进行改进，同时深入了解问题
  * 我们在每一轮调整中都使用自动搜索算法，并随着我们理解的增长不断更新我们的搜索空间
* 随着我们的探索，我们自然会找到越来越好的配置，因此我们的“最佳”模型将不断改进。
  * 当我们更新我们的最佳配置时，我们将其称为一次**发布**（这可能对应于也可能不对应于生产模型的实际发布）。
  * 对于每次发布，我们必须确保更改是基于强有力的证据——而不仅仅是基于幸运配置的随机机会——这样我们就不会给训练管道增加不必要的复杂性。

在高层次上，我们的增量调优策略涉及重复以下四个步骤：

1. 为下一轮实验确定范围适当的目标。
2. 设计并运行一组实验，朝着这个目标取得进展。
3. 从结果中了解我们能做什么。
4. 考虑是否推出新的最佳配置。  

本节的其余部分将更详细地考虑该策略

### 探索与开发（Exploration vs exploitation）

***总结***：大多数时候，我们的主要目标是深入了解问题

* 尽管有人可能认为我们会花费大部分时间来尝试最大化验证集的性能，但实际上我们花费了大部分时间来尝试深入了解问题，而贪婪地关注验证误差的时间相对较少。
  * 也就是说，我们大部分时间都花在了“探索”上，只有一小部分时间花在了“开发”上。
* 从长远来看，如果我们想最大化我们的最终表现，理解问题是至关重要的。 将洞察力置于短期收益之上可以帮助我们：
  * 避免只是在历史事件中偶然好的性能，就发布不必要的更改
  * 确定验证误差对哪些超参数最敏感，哪些超参数交互最多，因此需要一起重新调整，以及哪些超参数对其他变化相对不敏感，因此可以在未来的实验中修复。
  * 建议尝试使用潜在的新功能，例如，在出现过拟合问题时使用新的正则化。
  * 确定无用的特征，因此可以将其删除，从而降低未来实验的复杂性。
  * 识别来自超参数调整的改进何时可能已经饱和。
  * 围绕最佳值缩小我们的搜索空间，以提高调整效率。
* 当我们最终准备好变得贪婪时，我们可以完全关注验证误差，即使实验没有提供关于调优问题结构的最大信息

### 选择下一轮实验的目标

***总结***：每轮实验都应该有一个明确的目标，并且范围要足够窄，这样实验才能真正朝着目标取得进展

* 每轮实验都应该有一个明确的目标，并且范围要足够窄，这样实验才能真正朝着目标取得进展：如果我们试图一次添加多个特征或回答多个问题，我们可能无法理清每个对结果的影响。
* 示例目标包含：
  * 尝试对管道进行潜在的改进（例如，新的正则化器、预处理选择等）。
  * 了解特定模型超参数（例如激活函数）的影响
  * 贪婪地最大化验证错误。

### 设计下一轮实验

***总结***：确定哪些超参数对于实验目标而言是科学的、冗余的和固定的超参数。 创建一系列研究以比较科学超参数的不同值，同时优化麻烦的超参数。 选择冗余的超参数的搜索空间以平衡资源成本与科学价值。

#### 识别科学的、冗余的和固定的超参数

* 对于给定的目标，所有超参数要么是科学超参数，要么是冗余超参数，要么是固定超参数。
  * 科学超参数是那些对我们试图衡量的模型性能有影响的参数。
  * 冗余的超参数是那些需要优化的超参数，以便公平地比较科学超参数的不同值。 这类似于冗余参数的统计概念。
  * 固定超参数将在当前轮次实验中固定其值。 在比较科学超参数的不同值时，这些超参数的值不需要（或者我们不希望它们）改变。
    * 通过为一组实验固定某些超参数，我们必须接受从实验得出的结论可能对固定超参数的其他设置无效。 换句话说，固定的超参数对我们从实验中得出的任何结论提出警告
* 例如，如果我们的目标是“确定具有更多隐藏层的模型是否会减少验证误差”，那么隐藏层数就是一个科学的超参数。
  * 学习率是一个冗余的超参数，因为如果对每个层数分别调整学习率（最佳学习率通常取决于模型架构），我们只能公平地比较具有不同隐藏层数的模型。
  * 如果我们在之前的实验中确定激活函数的最佳选择对模型深度不敏感，或者如果我们愿意限制我们关于隐藏层数量的结论以仅涵盖该特定选择，则激活函数可以是一个固定的超参数。 或者，如果我们准备为每个隐藏层数单独调整它，它可能是一个冗余的参数。
* 一个特定的超参数是科学超参数、冗余超参数还是固定超参数并不是该超参数固有的，而是根据实验目标而变化的。
  * 例如，激活函数的选择可以是一个科学的超参数（对于我们的问题，ReLU 或 tanh 是更好的选择吗？），一个冗余的超参数（当我们允许多个模型时，最好的 5 层模型是否优于最好的 6 层模型？ 不同的可能激活函数？），或固定的超参数（对于 ReLU 网络，在特定位置添加批量归一化是否有帮助？）
* 在设计新一轮实验时，我们首先确定我们实验目标的科学超参数。
  * 在此阶段，我们将所有其他超参数视为冗余的超参数。
* 接下来，我们将一些冗余的超参数转换为固定超参数。
  * 如果有了无限的资源，我们会将所有非科学的超参数保留为冗余的超参数，这样我们从实验中得出的结论就不会受到关于固定超参数值的警告。
  * 然而，我们尝试调整的冗余的超参数越多，我们无法针对科学超参数的每个设置充分调整它们并最终从我们的实验中得出错误结论的风险就越大。
    * 如下所述，我们可以通过增加计算预算来应对这种风险，但通常我们的最大资源预算少于调整所有非科学超参数所需的资源预算。
  * 我们选择将一个冗余的超参数转换为一个固定的超参数，根据我们的判断，固定它所引入的警告比将它作为一个冗余的超参数包含在内的成本要小。
  * 给定的冗余超参数与科学超参数的交互越多，固定其值的破坏性就越大。 例如，权重衰减强度的最佳值通常取决于模型大小，因此假设权重衰减的单个特定值以比较不同的模型大小不会很有见地。
* 尽管我们分配给每个超参数的类型取决于实验目标，但我们对某些类别的超参数有以下经验法则：
  * 在各种优化器超参数（例如学习率、动量、学习率调度参数、Adam beta 等）中，至少其中一些是冗余的超参数，因为它们往往与其他变化的交互作用最大。
    * 它们很少是科学超参数，因为像“当前管道的最佳学习率是多少？”这样的目标。 没有给出太多的见解——最好的设置很容易随着下一次管道的改变而改变。
    * 尽管由于资源限制或当我们有特别有力的证据表明它们不与科学参数相互作用时，我们可能偶尔会修复其中一些，但我们通常应该假设优化器超参数必须单独调整以在不同设置之间进行公平比较 科学的超参数，因此不应该被固定。
      * 此外，我们没有先验理由偏爱一个优化器超参数值而不是另一个（例如，它们通常不会以任何方式影响前向传递或梯度的计算成本）
  * 相比之下，优化器的选择通常是科学超参数或固定超参数。
    * 如果我们的实验目标涉及在两个或多个不同的优化器之间进行公平比较（例如“确定哪个优化器在给定的步骤数中产生最低的验证错误”），那么它就是一个科学的超参数。
    * 或者，我们可能出于各种原因将其设为固定的超参数，包括（1）先前的实验使我们相信针对我们问题的最佳优化器对当前的科学超参数不敏感； 和/或（2）我们更喜欢使用这个优化器来比较科学超参数的值，因为它的训练曲线更容易推理； 和/或 (3) 我们更喜欢使用这个优化器，因为它比其他优化器使用更少的内存。
  * 正则化技术引入的超参数通常是冗余的超参数，但我们是否完全包括正则化技术是一个科学的或固定的超参数。
    * 例如，dropout 增加了代码的复杂性，因此在决定是否包含它时，我们会将“no dropout”与“dropout”作为一个科学的超参数，而将 dropout 率作为一个冗余的超参数。
      * 如果我们决定根据这个实验将 dropout 添加到我们的管道中，那么在未来的实验中，dropout 率将是一个冗余的超参数。
  * 架构超参数通常是科学的或固定的超参数，因为架构变化会影响服务和训练成本、延迟和内存需求。
    * 例如，层数通常是一个科学的或固定的超参数，因为它往往会对训练速度和内存使用产生巨大影响。
* 在某些情况下，干扰和固定超参数集将取决于科学超参数的值。
  * 例如，假设我们试图确定 Nesterov momentum 和 Adam 中哪个优化器的验证错误率最低。 科学超参数是优化器，它取值 {"Nesterov_momentum", "Adam"}。 值 optimizer="Nesterov_momentum" 引入了干扰/固定超参数 {learning_rate, momentum}，但值 optimizer="Adam" 引入了干扰/固定超参数 {learning_rate, beta1, beta2, epsilon}。
  * 仅针对科学超参数的某些值存在的超参数称为**条件超参数**。
  * 我们不应该仅仅因为两个条件超参数具有相同的名称就认为它们是相同的！ 在上面的示例中，名为 learning_rate 的条件超参数是 optimizer="Nesterov_momentum" 与 optimizer="Adam" 的不同超参数。 它在两种算法中的作用相似（尽管不完全相同），但在每个优化器中运行良好的值范围通常相差几个数量级。

#### 创建一组研究

* 一旦我们确定了科学和冗余的超参数，我们就会设计一个“研究”或一系列研究，以朝着实验目标取得进展。
  * 一项研究指定了一组要运行的超参数配置以供后续分析。 每个配置称为“试验”。
  * 创建研究通常涉及选择在试验中会有所不同的超参数，选择这些超参数可以采用的值（“搜索空间”），选择试验次数，以及选择自动搜索算法以从搜索空间中抽取那么多试验。 或者，我们可以通过手动指定一组超参数配置来创建研究
* 研究的目的是使用不同的科学超参数值运行管道，同时“优化掉”（或“优化”）冗余的超参数，以便科学超参数的不同值之间的比较是尽可能公平的。
* 在最简单的情况下，我们将对科学参数的每个配置进行单独研究，其中每个研究都会调整冗余的超参数。
  * 例如，如果我们的目标是从 Nesterov momentum 和 Adam 中选择最佳优化器，我们可以创建一个研究，其中 optimizer="Nesterov_momentum" 和冗余的超参数是 {learning_rate, momentum}，以及另一个研究，其中 optimizer=" Adam”和冗余的超参数是 {learning_rate, beta1, beta2, epsilon}。 我们将通过从每项研究中选择表现最好的试验来比较这两个优化器。
  * 我们可以使用任何无梯度优化算法，包括贝叶斯优化或进化算法等方法来优化多余的超参数，尽管我们更喜欢在调整的探索阶段使用准随机搜索，因为它具有多种优势 在此设置中。 探索结束后，如果有最先进的贝叶斯优化软件可用，那是我们的首选。
* 在更复杂的情况下，我们想要比较大量科学超参数的值，而进行那么多独立研究是不切实际的，我们可以将科学参数包含在与冗余超参数相同的搜索空间中，并使用搜索算法 在单个研究中对科学超参数和冗余超参数的值进行采样。
  * 采用这种方法时，条件超参数可能会导致问题，因为很难指定搜索空间，除非冗余超参数集对于科学超参数的所有值都相同。
  * 在这种情况下，我们更倾向于使用准随机搜索而不是更高级的黑盒优化工具，因为它确保我们获得相对均匀的科学超参数值采样。 无论搜索算法如何，我们都需要以某种方式确保它统一搜索科学参数。

#### 在信息丰富和负担得起的实验之间取得平衡

* 在设计一项研究或一系列研究时，我们需要分配有限的预算，以充分实现以下三个要求：
  1. 比较科学超参数的足够多的不同值。
  2. 在足够大的搜索空间上调整冗余的超参数。
  3. 对有害超参数的搜索空间进行密集采样
* 我们越能实现这三个必要条件，我们就能从实验中获得越多的洞察力。
  * 尽可能多地比较科学超参数的值可以拓宽我们从实验中获得的见解的范围。
  * 包括尽可能多的无用超参数并允许每个冗余超参数在尽可能宽的范围内变化可以增加我们的信心，即在科学超参数的每个配置的搜索空间中存在冗余超参数的“好”值。
    * 否则，我们可能会通过不搜索冗余参数空间的可能区域来对科学超参数的值进行不公平的比较，在这些区域中，科学参数的某些值可能有更好的值
  * 尽可能密集地对冗余超参数的搜索空间进行采样增加了我们的信心，即搜索过程会找到恰好存在于我们的搜索空间中的冗余超参数的任何良好设置。
    * 否则，我们可能会在科学参数的值之间进行不公平的比较，因为一些值随着冗余的超参数的采样而变得更幸运。
* 不幸的是，这三个维度中任何一个的改进都需要增加试验次数，从而增加资源成本，或者找到一种方法来节省其他维度之一的资源。
  * 每个问题都有自己的特性和计算限制，因此如何在这三个需求之间分配资源需要一定程度的领域知识。
  * 在进行一项研究后，我们总是试图了解该研究是否对冗余的超参数进行了足够好的调整（即搜索了足够大的空间，足够广泛）以公平地比较科学超参数（如下面更详细的描述）。

### 从试验结果中获取洞察力

***总结***：*除了努力实现每组实验的最初科学目标外，还要有检查额外问题的清单，如果发现问题，修改实验并重新运行*。

* 最终，每组实验都有一个特定的目标，我们想要评估实验为该目标提供的证据。
  * 然而，如果我们提出正确的问题，我们通常会发现在一组给定的实验能够朝着最初的目标取得很大进展之前需要纠正的问题。
    * 如果我们不提出这些问题，可能会得到不正确的答案
  * 由于运行实验的成本很高，我们还希望借此机会从每组实验中提取其他有用的见解，即使这些见解与当前目标并不直接相关。
* 在分析一组给定的实验以朝着最初的目标取得进展之前，我们应该问自己以下额外的问题：
  * 搜索空间是否足够大？
    * 如果研究的最佳点在一维或多维搜索空间的边界附近，则搜索可能不够广泛。 在这种情况下，我们应该进行另一项扩展后搜索空间的研究。
  * 我们是否从搜索空间中采样了足够多的点？
    * 如果没有，则运行更多的点，或者降低调节目标的期望。
  * 每项研究中有多少试验是不可行的（即出现分歧的试验，得到非常糟糕的损失值，或者因为它们违反了某些隐式约束而根本无法运行）？
    * 当研究中的很大一部分点不可行时，我们应该尝试调整搜索空间以避免对这些点进行采样，这有时需要重新参数化搜索空间。
    * 在某些情况下，大量不可行点可能表示训练代码中存在错误。
  * 该模型是否存在优化问题？
  * 我们可以从最佳试验的训练曲线中学到什么？
    * 例如，最好的试验是否具有与有问题的过度拟合一致的训练曲线？
* 如有必要，根据上述问题的答案，改进最近的研究（或研究组）以改进搜索空间和/或抽样更多试验，或采取其他一些纠正措施。
* 一旦我们回答了上述问题，我们就可以继续评估实验为我们最初的目标提供的证据（例如，评估更改是否有用）。

#### 识别差的搜索空间边界

* 如果从中采样的最佳点靠近其边界，则搜索空间是可疑的。 如果我们朝那个方向扩大搜索范围，我们可能会找到更好的点。
* 为了检查搜索空间边界，我们喜欢在我们称之为基本超参数轴图的地方绘制完成的试验，我们在其中绘制验证目标值与其中一个超参数（例如学习率）的关系。 图中的每个点都对应于一次试验。
  * 每次试验的验证目标值通常应该是它在训练过程中获得的最佳值。

![pic-1](pic/pic-1.png)

* 图 1 中的图表显示了误差率（越低越好）与初始学习率的关系。
* 如果最佳点聚集到搜索空间的边缘（在某个维度上），则可能需要扩展搜索空间边界，直到最佳观察点不再靠近边界。
* 通常，一项研究将包括“不可行”的试验，这些试验会产生分歧或得到非常糟糕的结果（在上图中用红色 X 标记）。
  * 如果学习率大于某个阈值的所有试验都不可行，并且如果表现最好的试验的学习率处于该区域的边缘，则该模型可能会遇到稳定性问题，从而无法获得更高的学习率。

#### 没有在搜索空间内采样足够多的点

* 通常，很难知道搜索空间的采样是否足够密集。 🤖
* 运行更多的试验当然更好，但代价是显而易见的。
* 由于很难知道我们什么时候采样足够，我们通常会采样我们可以负担得起的东西，并尝试通过反复查看各种超参数轴图来校准我们的直觉信心，并试图了解有多少点处于搜索空间的“良好”区域。

#### 检查训练曲线

***总结***：检查训练曲线是识别常见故障模式的一种简单方法，可以帮助我们确定下一步优先采取什么行动。

* 虽然在许多情况下，我们实验的主要目标只需要考虑每次试验的验证误差，但在将每次试验数量减少到个位数时我们必须小心，因为它可以隐藏有关表面下发生的事情的重要细节。
* 对于每项研究，我们总是至少查看少数最佳试验的训练曲线（绘制的训练误差和验证误差与训练期间训练步骤的关系）。
* 即使这不是解决主要实验目标所必需的，检查训练曲线也是识别常见失败模式的一种简单方法，并且可以帮助我们确定下一步优先采取什么行动。
* 在检查训练曲线时，我们对以下问题感兴趣。
* 是否有任何试验表现出有问题的过度拟合？
  * 当验证错误在训练期间的某个时刻开始增加时，就会出现有问题的过度拟合。
  * 在我们通过为每个科学超参数设置选择“最佳”试验来优化多余超参数的实验设置中，我们应该至少在每个与我们所比较的科学超参数设置相对应的最佳试验中检查有问题的过度拟合。
    * 如果任何最佳试验出现过拟合问题，我们通常希望在比较科学超参数的值之前使用额外的正则化技术重新运行实验和/或更好地调整现有的正则化参数。
      * 如果科学超参数包括正则化参数，这可能不适用，因为如果这些正则化参数的低强度设置导致有问题的过度拟合，也就不足为奇了。
    * 使用常见的正则化技术减少过度拟合通常很简单，这些技术会增加最小的代码复杂性或额外的计算（例如丢失、标签平滑、权重衰减），因此在下一轮实验中添加一个或多个这些通常没什么大不了的。
    * 例如，如果科学超参数是“隐藏层数”，并且使用最大隐藏层数的最佳试验表现出过拟合问题，那么我们通常更愿意使用额外的正则化再次尝试，而不是立即选择较小数量的 隐藏层。
    * 即使“最佳”试验都没有表现出有问题的过度拟合，如果它出现在其他任何试验中，也可能仍然存在问题。
      * 选择最佳试验会抑制出现过拟合问题的配置，并偏向那些不会出现过拟合问题的配置。 换句话说，它将支持具有更多正则化的配置。
      * 然而，任何让训练变得更糟的事情都可以作为正则化器，即使它不是故意的。 例如，选择较小的学习率可以通过阻碍优化过程来规范训练，但我们通常不希望以这种方式选择学习率。
      * 因此，我们必须意识到，科学超参数的每个设置的“最佳”试验可能会以有利于某些科学或冗余的超参数的“坏”值的方式选择。
* 训练后期的训练或验证误差是否存在高步进方差（high step-to-step variance）？
  * 如果是这样，这可能会干扰我们比较科学超参数的不同值的能力（因为每个试验随机地以“幸运”或“不幸”步骤结束）以及我们在生产中重现最佳试验结果的能力（因为 生产模型可能不会以与研究中相同的“幸运”步骤结束）。
  * 步进方差的最可能原因是批次方差（从每个批次的训练集中随机抽取示例）、小验证集以及在训练后期使用过高的学习率。
  * 可能的补救措施包括增加批量大小、获取更多验证数据、使用学习率衰减或使用 Polyak 平均。
* 训练结束时试验是否仍在改进？
  * 如果是这样，这表明我们处于“计算限制”状态，我们可能会从增加训练步骤数或改变学习率计划中受益。
* 训练集和验证集的性能在最后的训练步骤之前很早就饱和了吗？
  * 如果是这样，这表明我们处于“不受计算限制”的状态，并且我们可以减少训练步骤的数量。
* 虽然我们不能一一列举，但还有许多其他行为可以通过检查训练曲线变得明显（例如，训练过程中训练损失增加通常表明训练管道中存在错误）。

#### 使用隔离图（isolation plots）检测更改是否有用

![pic-2](pic/pic-2.png)

